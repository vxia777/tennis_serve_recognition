{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code is quite manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocal-bolivia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Lambda, Dropout\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from data_utils import DataSet\n",
    "from model.lstm_model import LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-requirement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eleven-geology",
   "metadata": {},
   "source": [
    "# Evaluating Hyperparameters for InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aware-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is pre-trained using the InceptionV3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-conversion",
   "metadata": {},
   "source": [
    "### ---- LOAD PARAMETERS FOR TRAINING ---- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "headed-dress",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_path = os.path.join('model','params.json')\n",
    "\n",
    "with open(json_path) as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "    learning_rate = params['learning_rate']\n",
    "    decay = params['decay']\n",
    "\n",
    "    hidden_units = params['hidden_units']\n",
    "    dense_units = params['dense_units']\n",
    "\n",
    "    reg = params['reg']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "    nb_epoch = params['nb_epoch']\n",
    "\n",
    "    # --- other parameters --- #\n",
    "    train_size = params['train_size']\n",
    "    num_classes = params['num_classes']\n",
    "    seq_length = params['seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confirmed-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters to try\n",
    "\n",
    "# # --- LEARNING RATES --- #\n",
    "# learning_rates = [1e-7, 1e-5, 1e-3]  \n",
    "\n",
    "# # --- BATCH SIZES --- #\n",
    "# batch_sizes = [2**3, 2**5, 2**7, 2**9] \n",
    "\n",
    "# --- HIDDEN UNITS --- #\n",
    "# num_hidden = [128, 256, 512]\n",
    "\n",
    "# --- DENSE UNITS --- #\n",
    "# num_dense = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-wright",
   "metadata": {},
   "source": [
    "### --- TRAIN & EVAL  (VARY LEARNING RATE AND BATCH SIZE) --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satellite-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "\n",
    "dataset = DataSet(None, seq_length)\n",
    "(x_train, y_train) = dataset.get_extracted_sequences('train', 1)\n",
    "(x_val, y_val) = dataset.get_extracted_sequences('validation', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "constitutional-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-07 and Bath size: 8\n",
      "13/13 [==============================] - 1s 37ms/step - loss: 1.0914 - categorical_accuracy: 0.3914\n",
      "Train Loss: 1.091\n",
      "Train Accuracy: 0.391\n",
      "\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1056 - categorical_accuracy: 0.3333\n",
      "Val Loss: 1.106\n",
      "Val Accuracy: 0.333\n",
      "\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1158 - categorical_accuracy: 0.3137\n",
      "Test Loss: 1.116\n",
      "Test Accuracy: 0.314\n",
      "\n",
      "Learning rate: 1e-07 and Bath size: 32\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 1.0988 - categorical_accuracy: 0.3434\n",
      "Train Loss: 1.099\n",
      "Train Accuracy: 0.343\n",
      "\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1205 - categorical_accuracy: 0.3333\n",
      "Val Loss: 1.120\n",
      "Val Accuracy: 0.333\n",
      "\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1096 - categorical_accuracy: 0.2549\n",
      "Test Loss: 1.110\n",
      "Test Accuracy: 0.255\n",
      "\n",
      "Learning rate: 1e-07 and Bath size: 128\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.1203 - categorical_accuracy: 0.3434\n",
      "Train Loss: 1.120\n",
      "Train Accuracy: 0.343\n",
      "\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1081 - categorical_accuracy: 0.3958\n",
      "Val Loss: 1.108\n",
      "Val Accuracy: 0.396\n",
      "\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1413 - categorical_accuracy: 0.2157\n",
      "Test Loss: 1.141\n",
      "Test Accuracy: 0.216\n",
      "\n",
      "Learning rate: 1e-07 and Bath size: 512\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.1124 - categorical_accuracy: 0.3157\n",
      "Train Loss: 1.112\n",
      "Train Accuracy: 0.316\n",
      "\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1049 - categorical_accuracy: 0.3333\n",
      "Val Loss: 1.105\n",
      "Val Accuracy: 0.333\n",
      "\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1023 - categorical_accuracy: 0.3725\n",
      "Test Loss: 1.102\n",
      "Test Accuracy: 0.373\n",
      "\n",
      "Learning rate: 1e-05 and Bath size: 8\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 0.3034 - categorical_accuracy: 0.9545\n",
      "Train Loss: 0.303\n",
      "Train Accuracy: 0.955\n",
      "\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3656 - categorical_accuracy: 0.3542\n",
      "Val Loss: 1.366\n",
      "Val Accuracy: 0.354\n",
      "\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3846 - categorical_accuracy: 0.4510\n",
      "Test Loss: 1.385\n",
      "Test Accuracy: 0.451\n",
      "\n",
      "Learning rate: 1e-05 and Bath size: 32\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 0.5158 - categorical_accuracy: 0.8737\n",
      "Train Loss: 0.516\n",
      "Train Accuracy: 0.874\n",
      "\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2378 - categorical_accuracy: 0.3750\n",
      "Val Loss: 1.238\n",
      "Val Accuracy: 0.375\n",
      "\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2043 - categorical_accuracy: 0.4510\n",
      "Test Loss: 1.204\n",
      "Test Accuracy: 0.451\n",
      "\n",
      "Learning rate: 1e-05 and Bath size: 128\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 0.9189 - categorical_accuracy: 0.6212\n",
      "Train Loss: 0.919\n",
      "Train Accuracy: 0.621\n",
      "\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1775 - categorical_accuracy: 0.3125\n",
      "Val Loss: 1.177\n",
      "Val Accuracy: 0.312\n",
      "\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1935 - categorical_accuracy: 0.2745\n",
      "Test Loss: 1.194\n",
      "Test Accuracy: 0.275\n",
      "\n",
      "Learning rate: 1e-05 and Bath size: 512\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 0.8969 - categorical_accuracy: 0.6540\n",
      "Train Loss: 0.897\n",
      "Train Accuracy: 0.654\n",
      "\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3145 - categorical_accuracy: 0.2708\n",
      "Val Loss: 1.315\n",
      "Val Accuracy: 0.271\n",
      "\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2248 - categorical_accuracy: 0.2549\n",
      "Test Loss: 1.225\n",
      "Test Accuracy: 0.255\n",
      "\n",
      "Learning rate: 0.001 and Bath size: 8\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 0.2403 - categorical_accuracy: 0.9192\n",
      "Train Loss: 0.240\n",
      "Train Accuracy: 0.919\n",
      "\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9740 - categorical_accuracy: 0.3750\n",
      "Val Loss: 1.974\n",
      "Val Accuracy: 0.375\n",
      "\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.5507 - categorical_accuracy: 0.4510\n",
      "Test Loss: 1.551\n",
      "Test Accuracy: 0.451\n",
      "\n",
      "Learning rate: 0.001 and Bath size: 32\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 0.1193 - categorical_accuracy: 0.9798\n",
      "Train Loss: 0.119\n",
      "Train Accuracy: 0.980\n",
      "\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7950 - categorical_accuracy: 0.4167\n",
      "Val Loss: 1.795\n",
      "Val Accuracy: 0.417\n",
      "\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7017 - categorical_accuracy: 0.4902\n",
      "Test Loss: 1.702\n",
      "Test Accuracy: 0.490\n",
      "\n",
      "Learning rate: 0.001 and Bath size: 128\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 0.3094 - categorical_accuracy: 0.9141\n",
      "Train Loss: 0.309\n",
      "Train Accuracy: 0.914\n",
      "\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4275 - categorical_accuracy: 0.3750\n",
      "Val Loss: 1.427\n",
      "Val Accuracy: 0.375\n",
      "\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3831 - categorical_accuracy: 0.4706\n",
      "Test Loss: 1.383\n",
      "Test Accuracy: 0.471\n",
      "\n",
      "Learning rate: 0.001 and Bath size: 512\n",
      "13/13 [==============================] - 1s 36ms/step - loss: 0.6235 - categorical_accuracy: 0.7525\n",
      "Train Loss: 0.624\n",
      "Train Accuracy: 0.753\n",
      "\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.4944 - categorical_accuracy: 0.3125\n",
      "Val Loss: 1.494\n",
      "Val Accuracy: 0.312\n",
      "\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3124 - categorical_accuracy: 0.3725\n",
      "Test Loss: 1.312\n",
      "Test Accuracy: 0.373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        learning_rate = lr\n",
    "        batch_size = bs\n",
    "        # setup optimizer: ADAM algorithm\n",
    "        optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "        # metrics for judging performance of model\n",
    "        metrics = ['categorical_accuracy']\n",
    "\n",
    "        #lstm model\n",
    "        init = LSTM_model(hidden_units=hidden_units, dense_units=dense_units, reg=reg, dropout_rate=dropout_rate, seq_length=seq_length, num_classes=num_classes)\n",
    "        model = init.model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        x_test, y_test = dataset.get_extracted_sequences('test')\n",
    "\n",
    "        print(f'Learning rate: {learning_rate} and Bath size: {batch_size}')\n",
    "\n",
    "        score = model.evaluate(x=x_train, y=y_train, verbose=1)\n",
    "        print(\"Train Loss: %2.3f\" % score[0])\n",
    "        print(\"Train Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_val, y=y_val, verbose=1)\n",
    "        print(\"Val Loss: %2.3f\" % score[0])\n",
    "        print(\"Val Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_test, y=y_test, verbose=1)\n",
    "        print(\"Test Loss: %2.3f\" % score[0])\n",
    "        print(\"Test Accuracy: %1.3f\\n\" % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-leader",
   "metadata": {},
   "source": [
    "### --- TRAIN & EVAL (VARY MODEL SIZE)  --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sharing-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#hidden units: 128 and # dense units: 64\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 0.0594 - categorical_accuracy: 1.0000\n",
      "Train Loss: 0.059\n",
      "Train Accuracy: 1.000\n",
      "\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5678 - categorical_accuracy: 0.5208\n",
      "Val Loss: 1.568\n",
      "Val Accuracy: 0.521\n",
      "\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5001 - categorical_accuracy: 0.5098\n",
      "Test Loss: 1.500\n",
      "Test Accuracy: 0.510\n",
      "\n",
      "#hidden units: 128 and # dense units: 128\n",
      "13/13 [==============================] - 1s 37ms/step - loss: 0.0407 - categorical_accuracy: 1.0000\n",
      "Train Loss: 0.041\n",
      "Train Accuracy: 1.000\n",
      "\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5747 - categorical_accuracy: 0.4583\n",
      "Val Loss: 1.575\n",
      "Val Accuracy: 0.458\n",
      "\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3564 - categorical_accuracy: 0.5294\n",
      "Test Loss: 1.356\n",
      "Test Accuracy: 0.529\n",
      "\n",
      "#hidden units: 128 and # dense units: 256\n",
      "13/13 [==============================] - 1s 36ms/step - loss: 0.0956 - categorical_accuracy: 0.9899\n",
      "Train Loss: 0.096\n",
      "Train Accuracy: 0.990\n",
      "\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.0297 - categorical_accuracy: 0.4583\n",
      "Val Loss: 2.030\n",
      "Val Accuracy: 0.458\n",
      "\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6718 - categorical_accuracy: 0.4314\n",
      "Test Loss: 1.672\n",
      "Test Accuracy: 0.431\n",
      "\n",
      "#hidden units: 256 and # dense units: 64\n",
      "13/13 [==============================] - 2s 84ms/step - loss: 0.0698 - categorical_accuracy: 0.9975\n",
      "Train Loss: 0.070\n",
      "Train Accuracy: 0.997\n",
      "\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.6152 - categorical_accuracy: 0.4375\n",
      "Val Loss: 1.615\n",
      "Val Accuracy: 0.438\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.5508 - categorical_accuracy: 0.4510\n",
      "Test Loss: 1.551\n",
      "Test Accuracy: 0.451\n",
      "\n",
      "#hidden units: 256 and # dense units: 128\n",
      "13/13 [==============================] - 2s 98ms/step - loss: 0.0773 - categorical_accuracy: 0.9949\n",
      "Train Loss: 0.077\n",
      "Train Accuracy: 0.995\n",
      "\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.6187 - categorical_accuracy: 0.3750\n",
      "Val Loss: 1.619\n",
      "Val Accuracy: 0.375\n",
      "\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.5240 - categorical_accuracy: 0.4314\n",
      "Test Loss: 1.524\n",
      "Test Accuracy: 0.431\n",
      "\n",
      "#hidden units: 256 and # dense units: 256\n",
      "13/13 [==============================] - 2s 82ms/step - loss: 0.0712 - categorical_accuracy: 0.9975\n",
      "Train Loss: 0.071\n",
      "Train Accuracy: 0.997\n",
      "\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.8884 - categorical_accuracy: 0.4167\n",
      "Val Loss: 1.888\n",
      "Val Accuracy: 0.417\n",
      "\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.8635 - categorical_accuracy: 0.4314\n",
      "Test Loss: 1.864\n",
      "Test Accuracy: 0.431\n",
      "\n",
      "#hidden units: 512 and # dense units: 64\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.0353 - categorical_accuracy: 1.0000\n",
      "Train Loss: 0.035\n",
      "Train Accuracy: 1.000\n",
      "\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2.0108 - categorical_accuracy: 0.3958\n",
      "Val Loss: 2.011\n",
      "Val Accuracy: 0.396\n",
      "\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.6645 - categorical_accuracy: 0.5686\n",
      "Test Loss: 1.665\n",
      "Test Accuracy: 0.569\n",
      "\n",
      "#hidden units: 512 and # dense units: 128\n",
      "13/13 [==============================] - 2s 125ms/step - loss: 0.0431 - categorical_accuracy: 1.0000\n",
      "Train Loss: 0.043\n",
      "Train Accuracy: 1.000\n",
      "\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.6218 - categorical_accuracy: 0.4583\n",
      "Val Loss: 1.622\n",
      "Val Accuracy: 0.458\n",
      "\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7830 - categorical_accuracy: 0.4510\n",
      "Test Loss: 1.783\n",
      "Test Accuracy: 0.451\n",
      "\n",
      "#hidden units: 512 and # dense units: 256\n",
      "13/13 [==============================] - 2s 129ms/step - loss: 0.2026 - categorical_accuracy: 0.9419\n",
      "Train Loss: 0.203\n",
      "Train Accuracy: 0.942\n",
      "\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.6267 - categorical_accuracy: 0.4375\n",
      "Val Loss: 1.627\n",
      "Val Accuracy: 0.438\n",
      "\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.6157 - categorical_accuracy: 0.4706\n",
      "Test Loss: 1.616\n",
      "Test Accuracy: 0.471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nh in num_hidden:\n",
    "    for nd in num_dense: \n",
    "        hidden_units = nh\n",
    "        dense_units = nd\n",
    "        # setup optimizer: ADAM algorithm\n",
    "        optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "        # metrics for judging performance of model\n",
    "        metrics = ['categorical_accuracy']\n",
    "\n",
    "        #lstm model\n",
    "        init = LSTM_model(hidden_units=hidden_units, dense_units=dense_units, reg=reg, dropout_rate=dropout_rate, seq_length=seq_length, num_classes=num_classes)\n",
    "        model = init.model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        #fit model on training data\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        x_test, y_test = dataset.get_extracted_sequences('test')\n",
    "\n",
    "        #load saved model\n",
    "        #reconstructed_model = keras.models.load_model(\"m_save_path\")\n",
    "        print(f'#hidden units: {hidden_units} and # dense units: {dense_units}')\n",
    "\n",
    "        score = model.evaluate(x=x_train, y=y_train, verbose=1)\n",
    "        print(\"Train Loss: %2.3f\" % score[0])\n",
    "        print(\"Train Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_val, y=y_val, verbose=1)\n",
    "        print(\"Val Loss: %2.3f\" % score[0])\n",
    "        print(\"Val Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_test, y=y_test, verbose=1)\n",
    "        print(\"Test Loss: %2.3f\" % score[0])\n",
    "        print(\"Test Accuracy: %1.3f\\n\" % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "radical-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = [16, 32, 64]\n",
    "num_dense = [64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-thompson",
   "metadata": {},
   "source": [
    "### ------ TRAIN & EVAL  (EVEN SMALLER MODEL) ------ #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aggressive-apartment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#hidden units: 16 and # dense units: 64\n",
      "13/13 [==============================] - 1s 11ms/step - loss: 0.3161 - categorical_accuracy: 0.9394\n",
      "Train Loss: 0.316\n",
      "Train Accuracy: 0.939\n",
      "\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.3604 - categorical_accuracy: 0.3333\n",
      "Val Loss: 1.360\n",
      "Val Accuracy: 0.333\n",
      "\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.2620 - categorical_accuracy: 0.4118\n",
      "Test Loss: 1.262\n",
      "Test Accuracy: 0.412\n",
      "\n",
      "#hidden units: 32 and # dense units: 64\n",
      "13/13 [==============================] - 1s 12ms/step - loss: 0.2834 - categorical_accuracy: 0.8939\n",
      "Train Loss: 0.283\n",
      "Train Accuracy: 0.894\n",
      "\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.8340 - categorical_accuracy: 0.4167\n",
      "Val Loss: 1.834\n",
      "Val Accuracy: 0.417\n",
      "\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3760 - categorical_accuracy: 0.4902\n",
      "Test Loss: 1.376\n",
      "Test Accuracy: 0.490\n",
      "\n",
      "#hidden units: 64 and # dense units: 64\n",
      "13/13 [==============================] - 1s 15ms/step - loss: 0.0988 - categorical_accuracy: 0.9874\n",
      "Train Loss: 0.099\n",
      "Train Accuracy: 0.987\n",
      "\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6715 - categorical_accuracy: 0.3958\n",
      "Val Loss: 1.671\n",
      "Val Accuracy: 0.396\n",
      "\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4880 - categorical_accuracy: 0.4902\n",
      "Test Loss: 1.488\n",
      "Test Accuracy: 0.490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nh in num_hidden:\n",
    "    for nd in num_dense: \n",
    "        hidden_units = nh\n",
    "        dense_units = nd\n",
    "        # setup optimizer: ADAM algorithm\n",
    "        optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "        # metrics for judging performance of model\n",
    "        metrics = ['categorical_accuracy']\n",
    "\n",
    "        #lstm model\n",
    "        init = LSTM_model(hidden_units=hidden_units, dense_units=dense_units, reg=reg, dropout_rate=dropout_rate, seq_length=seq_length, num_classes=num_classes)\n",
    "        model = init.model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        x_test, y_test = dataset.get_extracted_sequences('test')\n",
    "\n",
    "        #load saved model\n",
    "        #reconstructed_model = keras.models.load_model(\"m_save_path\")\n",
    "        print(f'#hidden units: {hidden_units} and # dense units: {dense_units}')\n",
    "\n",
    "        score = model.evaluate(x=x_train, y=y_train, verbose=1)\n",
    "        print(\"Train Loss: %2.3f\" % score[0])\n",
    "        print(\"Train Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_val, y=y_val, verbose=1)\n",
    "        print(\"Val Loss: %2.3f\" % score[0])\n",
    "        print(\"Val Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "        score = model.evaluate(x=x_test, y=y_test, verbose=1)\n",
    "        print(\"Test Loss: %2.3f\" % score[0])\n",
    "        print(\"Test Accuracy: %1.3f\\n\" % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-likelihood",
   "metadata": {},
   "source": [
    "# Evaluating on data pre-trained using Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "familiar-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the hyperparameters that performed best on InceptionV3 pre-trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "british-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join('model','params.json')\n",
    "\n",
    "with open(json_path) as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "    learning_rate = params['learning_rate']\n",
    "    decay = params['decay']\n",
    "\n",
    "    hidden_units = params['hidden_units']\n",
    "    dense_units = params['dense_units']\n",
    "\n",
    "    reg = params['reg']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "    nb_epoch = params['nb_epoch']\n",
    "\n",
    "    # --- other parameters --- #\n",
    "    train_size = params['train_size']\n",
    "    num_classes = params['num_classes']\n",
    "    seq_length = params['seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alternate-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is pre-trained using the xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-magnet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = DataSet(None, seq_length)\n",
    "(x_train, y_train) = dataset.get_extracted_sequences('train', 2)\n",
    "(x_val, y_val) = dataset.get_extracted_sequences('validation', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fundamental-campaign",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#hidden units: 128 and # dense units: 128\n",
      "13/13 [==============================] - 1s 37ms/step - loss: 0.0178 - categorical_accuracy: 1.0000\n",
      "Train Loss: 0.018\n",
      "Train Accuracy: 1.000\n",
      "\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1201 - categorical_accuracy: 0.4583\n",
      "Val Loss: 2.120\n",
      "Val Accuracy: 0.458\n",
      "\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.9943 - categorical_accuracy: 0.5490\n",
      "Test Loss: 1.994\n",
      "Test Accuracy: 0.549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "# metrics for judging performance of model\n",
    "metrics = ['categorical_accuracy']\n",
    "\n",
    "#lstm model\n",
    "init = LSTM_model(hidden_units=hidden_units, dense_units=dense_units, reg=reg, dropout_rate=dropout_rate, seq_length=seq_length, num_classes=num_classes)\n",
    "model = init.model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "x_test, y_test = dataset.get_extracted_sequences('test', 2)\n",
    "\n",
    "print(f'#hidden units: {hidden_units} and # dense units: {dense_units}')\n",
    "\n",
    "score = model.evaluate(x=x_train, y=y_train, verbose=1)\n",
    "print(\"Train Loss: %2.3f\" % score[0])\n",
    "print(\"Train Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "score = model.evaluate(x=x_val, y=y_val, verbose=1)\n",
    "print(\"Val Loss: %2.3f\" % score[0])\n",
    "print(\"Val Accuracy: %1.3f\\n\" % score[1])\n",
    "\n",
    "score = model.evaluate(x=x_test, y=y_test, verbose=1)\n",
    "print(\"Test Loss: %2.3f\" % score[0])\n",
    "print(\"Test Accuracy: %1.3f\\n\" % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coral-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attempted-retention",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d7b0ca13c041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'flat_service'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kick_service'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'slice_service'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred_class' is not defined"
     ]
    }
   ],
   "source": [
    "# Y_pred_class = model.predict_classes(x_test)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "target_names = ['flat_service', 'kick_service', 'slice_service']\n",
    "print(classification_report(y_test_class, Y_pred_class, target_names=target_names))\n",
    "conf_matrix = confusion_matrix(Y_test_class, Y_pred_class)\n",
    "\n",
    "sns.set(font_scale=1.7)\n",
    "df_cm = pd.DataFrame(conf_matrix, index = [i for i in target_names],\n",
    "                  columns = [i for i in target_names])\n",
    "plt.figure(figsize = (8,5))\n",
    "ax = sns.heatmap(df_cm, annot=True)\n",
    "ax.set_xlabel('Predicted Class', fontsize=18, labelpad=20)\n",
    "ax.set_ylabel('True Class', fontsize=18, rotation=0, labelpad=55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-address",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
